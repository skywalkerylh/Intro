{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "import torch.utils.data as Data\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    # __init__ part is to define what the layer/ model would contain \n",
    "    #      (set attributes, add layers or parameters of layer/model)\n",
    "    # forward is to control the (training) dataflow or operation on data during training\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        \n",
    "        self.F1 = 8  # level one filter count \n",
    "        self.F2 = 16 # level two filter count\n",
    "        self.D = 2   # depthwise multiplier for doing depthwise convolution\n",
    "\n",
    "        self.conv1 = nn.Sequential( \n",
    "            nn.Conv2d(1, self.F1, (1, 64), padding=(0, 32), bias=False),\n",
    "            nn.BatchNorm2d(self.F1)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(self.F1, self.D*self.F1, (22, 1), groups=self.F1, bias=False),\n",
    "            nn.BatchNorm2d(self.D*self.F1),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.Conv3 = nn.Sequential(\n",
    "            nn.Conv2d(self.D*self.F1, self.D*self.F1, (1, 16), padding=(0, 8), groups=self.D*self.F1, bias=False),\n",
    "            nn.Conv2d(self.D*self.F1, self.F2, (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(16*17, 4, bias=True) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.Conv3(x)\n",
    "        \n",
    "        x = x.view(-1, 16*17)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShallowConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 40, (1, 13), bias=False)\n",
    "        self.conv2 = nn.Conv2d(40, 40, (22, 1), bias=False)\n",
    "        self.Bn1   = nn.BatchNorm2d(40)\n",
    "        self.AvgPool1 = nn.AvgPool2d((1, 35), stride=(1, 7))\n",
    "        self.Drop1 = nn.Dropout(0.25)\n",
    "        self.classifier = nn.Linear(40*74, 4, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.Bn1(x)\n",
    "        x = x ** 2\n",
    "        x = self.AvgPool1(x)\n",
    "        x = torch.log(x)\n",
    "        x = self.Drop1(x)\n",
    "        x = x.view(-1, 40*74)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SCCNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 22, (22, 1))\n",
    "        self.Bn1 = nn.BatchNorm2d(22)\n",
    "        self.conv2 = nn.Conv2d(22, 20, (1, 12), padding=(0, 6))\n",
    "        self.Bn2   = nn.BatchNorm2d(20)\n",
    "        self.Drop1 = nn.Dropout(0.5)\n",
    "        self.AvgPool1 = nn.AvgPool2d((1, 62), stride=(1, 12))\n",
    "        self.classifier = nn.Linear(840, 4, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.Bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.Bn2(x)\n",
    "        x = x ** 2\n",
    "        x = self.Drop1(x)\n",
    "        x = self.AvgPool1(x)\n",
    "        x = torch.log(x)\n",
    "        x = x.view(-1, 840)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSception(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TSception, self).__init__()\n",
    "        self.pool = 8\n",
    "        self.Tception1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 9, (1,int(0.5 * 250))),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 8), (1, 8))\n",
    "            )\n",
    "        \n",
    "        self.Tception2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 9, (1,int(0.25 * 250))),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 8), (1, 8))\n",
    "            )\n",
    "        self.Tception3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 9, (1,int(0.0125 * 250))),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 8), (1, 8))\n",
    "            )\n",
    "\n",
    "        self.Sception1 = nn.Sequential(\n",
    "            nn.Conv2d(9, 6, (22,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 2), (1, 2))\n",
    "            )\n",
    "        \n",
    "        self.Sception2 = nn.Sequential(\n",
    "            nn.Conv2d(9, 6, (11,1), (11,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 2), (1, 2))\n",
    "            )\n",
    "        \n",
    "        self.BN_t = nn.BatchNorm2d(9)\n",
    "        self.BN_s = nn.BatchNorm2d(6)\n",
    "\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1674, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 4),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.Tception1(x)\n",
    "        x2 = self.Tception2(x)\n",
    "        x3 = self.Tception3(x)\n",
    "        x = torch.cat((x1,x2,x3), dim=-1)\n",
    "        x = self.BN_t(x)\n",
    "\n",
    "        x1 = self.Sception1(x)\n",
    "        x2 = self.Sception2(x)\n",
    "        x = torch.cat((x1, x2), dim=2)\n",
    "        x = self.BN_s(x)\n",
    "        x = x.view(-1, 1674)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSception_MI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TSception_MI, self).__init__()\n",
    "        self.Tception1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (1,32)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 4), (1, 4)),\n",
    "            nn.Dropout(0.3),\n",
    "            )\n",
    "        self.Tception2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (1,16)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 4), (1, 4)),\n",
    "            nn.Dropout(0.3),\n",
    "            )\n",
    "\n",
    "        self.Sception1 = nn.Sequential(\n",
    "            nn.Conv2d(8, 8, (22,1)),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AvgPool2d((1, 8), (1, 8)),\n",
    "            nn.Dropout(0.3),\n",
    "            )\n",
    "        \n",
    "        self.BN_t = nn.BatchNorm2d(8)\n",
    "        self.BN_s = nn.BatchNorm2d(8)\n",
    " \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(264, 125),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(125, 4),    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.Tception1(x)\n",
    "        x2 = self.Tception2(x)\n",
    "        x = torch.cat((x1,x2), dim=-1)\n",
    "        x = self.BN_t(x)\n",
    "        \n",
    "        x = self.Sception1(x)\n",
    "        x = self.BN_s(x)\n",
    "        x = x.view(-1, 264)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## individual subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoader_ID(sub = 1, batch = 32, shuffle = True):\n",
    "    \"\"\"\n",
    "    individual scheme\n",
    "    ------------------------------\n",
    "    parameters: \n",
    "        sub: the subject num\n",
    "        batch: batch size\n",
    "        shuffle: shuffle data or not\n",
    "    return:\n",
    "        train dataloader (288),1,22,562\n",
    "        test dataloader (288),1,22,562\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\nconstructing ID dataloader')\n",
    "    data_train = scipy.io.loadmat('BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(sub))\n",
    "    data_test = scipy.io.loadmat('BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(sub))\n",
    "\n",
    "    dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    x_train = torch.Tensor(data_train['x_train']).unsqueeze(1)\n",
    "    y_train = torch.Tensor(data_train['y_train']).view(-1).long()\n",
    "    x_test = torch.Tensor(data_test['x_test']).unsqueeze(1)\n",
    "    y_test = torch.Tensor(data_test['y_test']).view(-1).long()\n",
    "\n",
    "    print(f\"x_train size is: {x_train.size()}\")\n",
    "    print(f\"y_train size is: {y_train.size()}\")\n",
    "    print(f\"x_test size is: {x_test.size()}\")\n",
    "    print(f\"y_test size is: {y_test.size()}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device(\"cuda\")\n",
    "        num_worker = 0\n",
    "        x_train = x_train.to(dev)\n",
    "        y_train = y_train.to(dev)\n",
    "        x_test = x_test.to(dev)\n",
    "        y_test = y_test.to(dev)\n",
    "    else:\n",
    "        dev = torch.device(\"cpu\")\n",
    "        num_worker = 8\n",
    "\n",
    "    train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "    test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    trainloader = Data.DataLoader(\n",
    "        dataset = train_dataset,\n",
    "        batch_size = batch,\n",
    "        shuffle = shuffle,\n",
    "        num_workers = num_worker\n",
    "    )\n",
    "    testloader =  Data.DataLoader(\n",
    "        dataset = test_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        num_workers = num_worker,\n",
    "    )\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subject-independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoader_SI(subject=1, batch = 32, shuffle = True):\n",
    "     \"\"\"\n",
    "    subject independent scheme\n",
    "    ------------------------------\n",
    "    parameters: \n",
    "        sub: the testing subject num\n",
    "        batch: batch size\n",
    "        shuffle: shuffle data or not\n",
    "    return:\n",
    "        train dataloader (288*8),1,22,562\n",
    "        test dataloader (288),1,22,562\n",
    "    \"\"\"\n",
    "        \n",
    "    print('\\nconstructing SI dataloader')\n",
    "\n",
    "    Tname='BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(subject)\n",
    "    Ename='BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(subject)\n",
    "    data_train = scipy.io.loadmat(Tname)\n",
    "    data_test = scipy.io.loadmat(Ename)\n",
    "    x_tra = torch.Tensor(data_train['x_train']).unsqueeze(1)\n",
    "    y_tra = torch.Tensor(data_train['y_train']).view(-1).long()\n",
    "    x_te = torch.Tensor(data_test['x_test']).unsqueeze(1)\n",
    "    y_te = torch.Tensor(data_test['y_test']).view(-1).long()\n",
    "\n",
    "    for sub in range(1,10):\n",
    "        if sub==subject:\n",
    "            continue\n",
    "        else:\n",
    "            Tname='BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(sub)\n",
    "            Ename='BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(sub)\n",
    "        \n",
    "            T = scipy.io.loadmat(Tname)\n",
    "            E = scipy.io.loadmat(Ename)\n",
    "            x_tra = torch.cat((x_tra, torch.Tensor(T['x_train']).unsqueeze(1)), dim=0)\n",
    "            y_tra = torch.cat((y_tra, torch.Tensor(T['y_train']).view(-1).long()), dim=0)\n",
    "            x_te = torch.cat((x_te, torch.Tensor(E['x_test']).unsqueeze(1)), dim=0)\n",
    "            y_te = torch.cat((y_te, torch.Tensor(E['y_test']).view(-1).long()), dim=0)\n",
    "\n",
    "    \n",
    "    # first 288 is subject 1, needs to isolate from training data or extract as testing data\n",
    "    xT, yT = x_tra[288:], y_tra[288:] \n",
    "    xE, yE = x_te[288:], y_te[288:]\n",
    "    x_train = torch.cat((xT, xE),dim=0)\n",
    "    y_train = torch.cat((yT, yE), dim=0)\n",
    "    x_test = x_te[:288]\n",
    "    y_test = y_te[:288]\n",
    "\n",
    "    print(f\"x_train size is: {x_train.size()}\") \n",
    "    print(f\"y_train size is: {y_train.size()}\")\n",
    "    print(f\"x_test size is: {x_test.size()}\") \n",
    "    print(f\"y_test size is: {y_test.size()}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device(\"cuda\")\n",
    "        num_worker = 0\n",
    "        x_train = x_train.to(dev)\n",
    "        y_train = y_train.to(dev)\n",
    "        x_test = x_test.to(dev)\n",
    "        y_test = y_test.to(dev)\n",
    "    else:\n",
    "        dev = torch.device(\"cpu\")\n",
    "        num_worker = 8\n",
    "    \n",
    "    \n",
    "    train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "    test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    trainloader = Data.DataLoader(\n",
    "        dataset = train_dataset,\n",
    "        batch_size = batch,\n",
    "        shuffle = shuffle,\n",
    "        num_workers = num_worker\n",
    "    )\n",
    "    testloader =  Data.DataLoader(\n",
    "        dataset = test_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        num_workers = num_worker,\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subject-dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoader_SD(subject=1, batch = 32, shuffle = True):\n",
    "    \"\"\"\n",
    "    subject dependent scheme\n",
    "    ------------------------------\n",
    "    parameters: \n",
    "        sub: the testing subject num\n",
    "        batch: batch size\n",
    "        shuffle: shuffle data or not\n",
    "    return:\n",
    "        train dataloader (288*9),1,22,562\n",
    "        test dataloader (288),1,22,562\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\nconstructing SD dataloader')\n",
    "    \n",
    "    Tname='BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(subject)\n",
    "    Ename='BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(subject)\n",
    "    data_train = scipy.io.loadmat(Tname)\n",
    "    data_test = scipy.io.loadmat(Ename)\n",
    "    x_tra = torch.Tensor(data_train['x_train']).unsqueeze(1)\n",
    "    y_tra = torch.Tensor(data_train['y_train']).view(-1).long()\n",
    "    x_te = torch.Tensor(data_test['x_test']).unsqueeze(1)\n",
    "    y_te = torch.Tensor(data_test['y_test']).view(-1).long()\n",
    "\n",
    "    for sub in range(1,10):\n",
    "        if sub==subject:\n",
    "            continue\n",
    "        else:\n",
    "            Tname='BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(sub)\n",
    "            Ename='BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(sub)\n",
    "        \n",
    "            T = scipy.io.loadmat(Tname)\n",
    "            E = scipy.io.loadmat(Ename)\n",
    "            x_tra = torch.cat((x_tra, torch.Tensor(T['x_train']).unsqueeze(1)), dim=0)\n",
    "            y_tra = torch.cat((y_tra, torch.Tensor(T['y_train']).view(-1).long()), dim=0)\n",
    "            x_te = torch.cat((x_te, torch.Tensor(E['x_test']).unsqueeze(1)), dim=0)\n",
    "            y_te = torch.cat((y_te, torch.Tensor(E['y_test']).view(-1).long()), dim=0)\n",
    "\n",
    "    # first 288 is subject 1, needs to extract as testing\n",
    "    xE, yE = x_te[288:], y_te[288:]\n",
    "    x_train = torch.cat((x_tra, xE),dim=0)\n",
    "    y_train = torch.cat((y_tra, yE), dim=0)\n",
    "    x_test = x_te[:288]\n",
    "    y_test = y_te[:288]\n",
    " \n",
    "    print(f\"x_train size is: {x_train.size()}\") \n",
    "    print(f\"y_train size is: {y_train.size()}\")\n",
    "    print(f\"x_test size is: {x_test.size()}\") \n",
    "    print(f\"y_test size is: {y_test.size()}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device(\"cuda\")\n",
    "        num_worker = 0\n",
    "        x_train = x_train.to(dev)\n",
    "        y_train = y_train.to(dev)\n",
    "        x_test = x_test.to(dev)\n",
    "        y_test = y_test.to(dev)\n",
    "    else:\n",
    "        dev = torch.device(\"cpu\")\n",
    "        num_worker = 8\n",
    "    \n",
    "    \n",
    "    train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "    test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    trainloader = Data.DataLoader(\n",
    "        dataset = train_dataset,\n",
    "        batch_size = batch,\n",
    "        shuffle = shuffle,\n",
    "        num_workers = num_worker\n",
    "    )\n",
    "    testloader =  Data.DataLoader(\n",
    "        dataset = test_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        num_workers = num_worker,\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subject-independent plus fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLoader_FT(subject=1, batch = 32, shuffle = True):\n",
    "    \"\"\"\n",
    "    subject independent + fine-tuning scheme\n",
    "    ------------------------------\n",
    "    parameters: \n",
    "        subject: the testing subject num\n",
    "        batch: batch size\n",
    "        shuffle: shuffle data or not\n",
    "    return:\n",
    "        phase 1 train dataloader (288*8),1,22,562\n",
    "        phase 2 train dataloader (288),1,22,562\n",
    "        test dataloader (288),1,22,562\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\nconstructing SI+FT dataloader')\n",
    "\n",
    "    Tname='BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(subject)\n",
    "    Ename='BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(subject)\n",
    "    data_train = scipy.io.loadmat(Tname)\n",
    "    data_test = scipy.io.loadmat(Ename)\n",
    "    x_tra = torch.Tensor(data_train['x_train']).unsqueeze(1)\n",
    "    y_tra = torch.Tensor(data_train['y_train']).view(-1).long()\n",
    "    x_te = torch.Tensor(data_test['x_test']).unsqueeze(1)\n",
    "    y_te = torch.Tensor(data_test['y_test']).view(-1).long()\n",
    "\n",
    "    for sub in range(1,10):\n",
    "        if sub==subject:\n",
    "            continue\n",
    "        else:\n",
    "            Tname='BCICIV_2a_mat/BCIC_S{:0>2d}_T.mat'.format(sub)\n",
    "            Ename='BCICIV_2a_mat/BCIC_S{:0>2d}_E.mat'.format(sub)\n",
    "        \n",
    "            T = scipy.io.loadmat(Tname)\n",
    "            E = scipy.io.loadmat(Ename)\n",
    "            x_tra = torch.cat((x_tra, torch.Tensor(T['x_train']).unsqueeze(1)), dim=0)\n",
    "            y_tra = torch.cat((y_tra, torch.Tensor(T['y_train']).view(-1).long()), dim=0)\n",
    "            x_te = torch.cat((x_te, torch.Tensor(E['x_test']).unsqueeze(1)), dim=0)\n",
    "            y_te = torch.cat((y_te, torch.Tensor(E['y_test']).view(-1).long()), dim=0)\n",
    "\n",
    "    \n",
    "    # subject 2 - 9\n",
    "    xT, yT = x_tra[288:], y_tra[288:] # T data\n",
    "    xE, yE = x_te[288:], y_te[288:] # E data\n",
    "    x_train = torch.cat((xT, xE),dim=0)\n",
    "    y_train = torch.cat((yT, yE), dim=0)\n",
    "\n",
    "    # subject 1, for fine-tuning training and testing\n",
    "    x_train2 = x_tra[:288]\n",
    "    y_train2 = y_tra[:288]\n",
    "    x_test = x_te[:288]\n",
    "    y_test = y_te[:288]\n",
    "\n",
    "    print(f\"x_train size is: {x_train.size()}\") \n",
    "    print(f\"y_train size is: {y_train.size()}\")\n",
    "    print(f\"x_train2 size is: {x_train2.size()}\") \n",
    "    print(f\"y_train2 size is: {y_train2.size()}\")\n",
    "    print(f\"x_test size is: {x_test.size()}\") \n",
    "    print(f\"y_test size is: {y_test.size()}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device(\"cuda\")\n",
    "        num_worker = 0\n",
    "        x_train = x_train.to(dev)\n",
    "        y_train = y_train.to(dev)\n",
    "        x_train2 = x_train2.to(dev)\n",
    "        y_train2 = y_train2.to(dev)\n",
    "        x_test = x_test.to(dev)\n",
    "        y_test = y_test.to(dev)\n",
    "    else:\n",
    "        dev = torch.device(\"cpu\")\n",
    "        num_worker = 8\n",
    "    \n",
    "    \n",
    "    train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "    train2_dataset = Data.TensorDataset(x_train2, y_train2)\n",
    "    test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    trainloader = Data.DataLoader(\n",
    "        dataset = train_dataset,\n",
    "        batch_size = batch,\n",
    "        shuffle = shuffle,\n",
    "        num_workers = num_worker\n",
    "    )\n",
    "    trainloader2 = Data.DataLoader(\n",
    "        dataset = train2_dataset,\n",
    "        batch_size = batch,\n",
    "        shuffle = shuffle,\n",
    "        num_workers = num_worker\n",
    "    )\n",
    "    testloader =  Data.DataLoader(\n",
    "        dataset = test_dataset,\n",
    "        batch_size = 1,\n",
    "        shuffle = False,\n",
    "        num_workers = num_worker,\n",
    "    )\n",
    "\n",
    "    return trainloader, trainloader2, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, dataloader, epo = 200, lr = 0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "    \n",
    "    print('\\nstart training')\n",
    "    net.train()\n",
    "    for epoch in range(epo):\n",
    "        for xb, yb in dataloader:\n",
    "            pred = net(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"epoch {epoch+1} loss: {loss.item()}\")\n",
    "            \n",
    "def test(net, dataloader):\n",
    "    acc = 0\n",
    "    yTrue = []\n",
    "    yPred = []\n",
    "    \n",
    "    print('\\nstart testing')\n",
    "\n",
    "    net.eval()\n",
    "    for x, y in dataloader:\n",
    "        pred = net(x)\n",
    "        if pred.argmax() == y:\n",
    "            acc += 1\n",
    "            \n",
    "        yTrue.append(y)\n",
    "        yPred.append(pred.argmax())\n",
    "    \n",
    "    plotConfusionMatrix(yTrue, yPred ) \n",
    "    \n",
    "    acc /= len(dataloader)\n",
    "\n",
    "    print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def plotConfusionMatrix(y_true, y_pred, normalize=True):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\")/cm.sum(axis=1)[:,np.newaxis]\n",
    "    else:\n",
    "        cm = cm.astype(\"float\")/cm.sum()\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xticks(np.arange(4))\n",
    "    plt.yticks(np.arange(5))\n",
    "    plt.ylim(len(cm) - 0.5, -0.5)\n",
    "    \n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(x=j, y=i, s=(\"%.2f\"%cm[i][j]), va='center', ha='center')\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 problem1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # determine current hardware\n",
    "\n",
    "trainloader, testloader = getDataLoader_SI(batch = 32) # if not passing variables, default batch size 32\n",
    "eegnet = EEGNet().to(dev)                              # assign the network to specified hardware\n",
    "\n",
    "train(eegnet, trainloader, epo = 200, lr = 0.001)\n",
    "test(eegnet, testloader) \n",
    "\n",
    "summary(eegnet,(1, 22, 562)) # View network details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 problem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = 64\n",
    "# lr = 0.003\n",
    "# by adjusting the batch size and the learning rate, we can finish this problem.\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "trainloader, testloader = getDataLoader_SI(batch = 64)\n",
    "\n",
    "eegnet = EEGNet().to(dev) \n",
    "\n",
    "train(eegnet, trainloader,epo = 200, lr = 0.003)\n",
    "test(eegnet, testloader)\n",
    "\n",
    "summary(eegnet,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 problem3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with different schemes by using different dataloader functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* subject-independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "trainloader, testloader = getDataLoader_SI(batch = 32)\n",
    "\n",
    "sccnet = SCCNet().to(dev) \n",
    "\n",
    "train(sccnet, trainloader,epo = 200, lr = 0.001)\n",
    "test(sccnet, testloader)\n",
    "summary(sccnet,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* subject dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = getDataLoader_SD(batch = 32)\n",
    "\n",
    "sccnet = SCCNet().to(dev)\n",
    "\n",
    "train(sccnet, trainloader,epo = 200, lr = 0.001)\n",
    "test(sccnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* subject-independent plus fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, trainloader2, testloader = getDataLoader_FT(batch = 32)\n",
    "\n",
    "sccnet = SCCNet().to(dev)\n",
    "\n",
    "train(sccnet, trainloader,epo = 200, lr = 0.001)\n",
    "train(sccnet, trainloader2, epo = 200, lr = 0.001)\n",
    "test(sccnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 problem4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this part, we can just modify the parameter shuffle to False, and compare the results to previous results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for EEG individual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = getDataLoader_ID(batch = 32, shuffle = False)\n",
    "\n",
    "eegnet = EEGNet().to(dev) \n",
    "\n",
    "train(eegnet, trainloader, epo = 200, lr = 0.001)\n",
    "test(eegnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* for EEG subject dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader = getDataLoader_SD(batch = 32, shuffle = False)\n",
    "\n",
    "eegnet = EEGNet().to(dev) \n",
    "\n",
    "train(eegnet, trainloader,epo = 200, lr = 0.001)\n",
    "test(eegnet, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy: 25.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2 problem1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EEGnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#trainloader, testloader = getDataLoader_SI(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent scheme\n",
    "#trainloader, testloader = getDataLoader_ID(batch = 32, shuffle = True)\n",
    "#=================> if we run within subject scheme\n",
    "#trainloader, trainloader2, testloader = getDataLoader_FT(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent + fine-tuning scheme\n",
    "\n",
    "trainloader, testloader = getDataLoader_subject_dependent(batch = 32, shuffle = True)\n",
    "\n",
    "eegnet = EEGNet().to(dev)\n",
    "\n",
    "train(eegnet, trainloader,epo = 200, lr = 0.001)\n",
    "#train(eegnet, trainloader2,epo = 200, lr = 0.001) \n",
    "#=================> add this line if we run subject independent + fine-tuning scheme\n",
    "\n",
    "test(eegnet, testloader)\n",
    "summary(eegnet,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* shallow convolution net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader, testloader = getDataLoader_SI(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent scheme\n",
    "#trainloader, testloader = getDataLoader_ID(batch = 32, shuffle = True)\n",
    "#=================> if we run within subject scheme\n",
    "#trainloader, trainloader2, testloader = getDataLoader_FT(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent + fine-tuning scheme\n",
    "\n",
    "trainloader, testloader = getDataLoader_subject_dependent(batch = 32, shuffle = True)\n",
    "\n",
    "ShallowConvNet = ShallowConvNet().to(dev)\n",
    "\n",
    "train(ShallowConvNet, trainloader, epo = 200, lr = 0.001)\n",
    "#train(ShallowConvNet, trainloader2,epo = 200, lr = 0.001) \n",
    "#=================> add this line if we run subject independent + fine-tuning scheme\n",
    "\n",
    "test(ShallowConvNet, testloader)\n",
    "summary(ShallowConvNet,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sccnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader, testloader = getDataLoader_SI(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent scheme\n",
    "#trainloader, testloader = getDataLoader_ID(batch = 32, shuffle = True)\n",
    "#=================> if we run within subject scheme\n",
    "#trainloader, trainloader2, testloader = getDataLoader_FT(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent + fine-tuning scheme\n",
    "\n",
    "trainloader, testloader = getDataLoader_subject_dependent(batch = 32, shuffle = True)\n",
    "\n",
    "sccnet = SCCNet().to(dev)\n",
    "\n",
    "train(sccnet, trainloader, epo = 200, lr = 0.001)\n",
    "#train(sccnet, trainloader2,epo = 200, lr = 0.001) \n",
    "#=================> add this line if we run subject independent + fine-tuning scheme\n",
    "\n",
    "test(sccnet, testloader)\n",
    "summary(sccnet,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TSception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader, testloader = getDataLoader_SI(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent scheme\n",
    "#trainloader, testloader = getDataLoader_ID(batch = 32, shuffle = True)\n",
    "#=================> if we run within subject scheme\n",
    "#trainloader, trainloader2, testloader = getDataLoader_FT(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent + fine-tuning scheme\n",
    "\n",
    "trainloader, testloader = getDataLoader_subject_dependent(batch = 32, shuffle = True)\n",
    "\n",
    "tsception = TSception().to(dev)\n",
    "\n",
    "train(tsception, trainloader, epo = 200, lr = 0.001)\n",
    "#train(tsception, trainloader2,epo = 200, lr = 0.001) \n",
    "#=================> add this line if we run subject independent + fine-tuning scheme\n",
    "\n",
    "test(tsception, testloader)\n",
    "summary(tsception,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TSception we try to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainloader, testloader = getDataLoader_SI(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent scheme\n",
    "#trainloader, testloader = getDataLoader_ID(batch = 32, shuffle = True)\n",
    "#=================> if we run within subject scheme\n",
    "#trainloader, trainloader2, testloader = getDataLoader_FT(batch = 32, shuffle = True) \n",
    "#=================> if we run subject independent + fine-tuning scheme\n",
    "\n",
    "trainloader, testloader = getDataLoader_subject_dependent(batch = 32, shuffle = True)\n",
    "\n",
    "tsception_mi = TSception_MI().to(dev)\n",
    "\n",
    "train(tsception_mi, trainloader, epo = 200, lr = 0.001)\n",
    "#train(tsception, trainloader2,epo = 200, lr = 0.001) \n",
    "#=================> add this line if we run subject independent + fine-tuning scheme\n",
    "\n",
    "test(tsception, testloader)\n",
    "summary(tsception_mi,(1, 22, 562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
